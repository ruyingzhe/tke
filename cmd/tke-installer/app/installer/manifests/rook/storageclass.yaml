#################################################################################################################
# Define the settings for the rook-ceph cluster with settings that should only be used in a test environment.
# A single filestore OSD will be created in the dataDirHostPath.
# For example, to create the cluster:
#   kubectl create -f common.yaml
#   kubectl create -f operator.yaml
#   kubectl create -f cluster-test.yaml
#################################################################################################################

apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: rook-ceph
  namespace: rook-ceph
spec:
  cephVersion:
    image: ${CephImage}
    allowUnsupported: true
  dataDirHostPath: ${DataDirHostPath}
  skipUpgradeChecks: false
  mon:
    count: 1
    allowMultiplePerNode: true
  dashboard:
    enabled: true
    ssl: true
  monitoring:
    enabled: false  # requires Prometheus to be pre-installed
    rulesNamespace: rook-ceph
  network:
    hostNetwork: false
  rbdMirroring:
    workers: 0
  mgr:
    modules:
      # the pg_autoscaler is only available on nautilus or newer. remove this if testing mimic.
      - name: pg_autoscaler
        enabled: true
  storage:
    useAllNodes: true
    useAllDevices: false
    deviceFilter:
    config:
      databaseSizeMB: \"1024\" # this value can be removed for environments with normal sized disks (100 GB or larger)
      journalSizeMB: \"1024\"  # this value can be removed for environments with normal sized disks (20 GB or larger)
      osdsPerDevice: \"1\" # this value can be overridden at the node or device level
    directories:
      - path: ${DataDirHostPath}
#    nodes:
#    - name: "minikube"
#      directories:
#      - path: "/data/rook-dir"
#      devices:
#      - name: "sdb"
#      - name: "nvme01" # multiple osds can be created on high performance devices
#        config:
#          osdsPerDevice: "5"

---

apiVersion: ceph.rook.io/v1
kind: CephBlockPool
metadata:
  name: replicapool
  namespace: rook-ceph
spec:
  failureDomain: host
  replicated:
    size: ${PoolReplicas}
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rook-ceph-block
provisioner: rook-ceph.rbd.csi.ceph.com
parameters:
  # clusterID is the namespace where the rook cluster is running
  # If you change this namespace, also change the namespace below where the secret namespaces are defined
  clusterID: rook-ceph

  # Ceph pool into which the RBD image shall be created
  pool: replicapool

  # RBD image format. Defaults to "2".
  imageFormat: \"2\"

  # RBD image features. Available for imageFormat: "2". CSI RBD currently supports only layering feature.
  imageFeatures: layering

  # The secrets contain Ceph admin credentials. These are generated automatically by the operator
  # in the same namespace as the cluster.
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
  # Specify the filesystem type of the volume. If not specified, csi-provisioner
  # will set default as ext4.
  csi.storage.k8s.io/fstype: ext4
# uncomment the following to use rbd-nbd as mounter on supported nodes
#mounter: rbd-nbd
reclaimPolicy: Delete
